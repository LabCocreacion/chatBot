# Chatbot Instituto Nacional de CancerologÃ­a ğŸ¤–

Un asistente conversacional inteligente desarrollado para el **Laboratorio de Co-creaciÃ³n para la InnovaciÃ³n del Instituto Nacional de CancerologÃ­a**, utilizando tecnologÃ­a de OpenAI GPT-4o-mini.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa una API REST que permite interacciones conversacionales con un asistente de IA especializado en brindar informaciÃ³n y apoyo relacionado con el Instituto Nacional de CancerologÃ­a. El chatbot estÃ¡ diseÃ±ado para responder de manera clara, profesional y Ãºtil a las consultas de los usuarios.

### âœ¨ CaracterÃ­sticas Principales

- ğŸš€ **API REST rÃ¡pida y eficiente** basada en Flask
- ğŸ§  **IntegraciÃ³n con OpenAI GPT-4o-mini** para procesamiento de lenguaje natural
- ğŸŒ **CORS habilitado** para integraciÃ³n con aplicaciones frontend
- ğŸ—ï¸ **Arquitectura modular** con separaciÃ³n clara de responsabilidades
- âš¡ **ConfiguraciÃ³n simple** con variables de entorno
- ğŸ›¡ï¸ **Manejo robusto de errores** y validaciÃ³n de entrada

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.12** - Lenguaje de programaciÃ³n principal
- **Flask 3.1.1** - Framework web ligero
- **OpenAI 1.90.0** - SDK para integraciÃ³n con OpenAI API
- **Flask-CORS 6.0.1** - Manejo de Cross-Origin Resource Sharing
- **python-dotenv 1.1.0** - GestiÃ³n de variables de entorno

## ğŸ“ Estructura del Proyecto

```
chatBot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py          # Factory pattern y configuraciÃ³n de Flask
â”‚   â”œâ”€â”€ openai_service.py    # Servicio de integraciÃ³n con OpenAI
â”‚   â””â”€â”€ routes.py            # DefiniciÃ³n de endpoints REST
â”œâ”€â”€ config.py                # Configuraciones del proyecto
â”œâ”€â”€ requirements.txt         # Dependencias de Python
â”œâ”€â”€ run.py                   # Punto de entrada de la aplicaciÃ³n
â”œâ”€â”€ README.md               # DocumentaciÃ³n del proyecto
â””â”€â”€ MANUAL_TECNICO.md       # Manual tÃ©cnico detallado
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.8 o superior (recomendado Python 3.12)
- pip (gestor de paquetes de Python)
- Una API key vÃ¡lida de OpenAI

### 1. Clonar el repositorio

```bash
git clone https://github.com/LabCocreacion/chatBot.git
cd chatBot
```

### 2. Crear y activar entorno virtual

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno

Crear un archivo `.env` en la raÃ­z del proyecto:

```bash
OPENAI_API_KEY=tu_clave_de_openai_aqui
```

### 5. Ejecutar la aplicaciÃ³n

```bash
python run.py
```

La aplicaciÃ³n estarÃ¡ disponible en: `http://localhost:5003`

## ğŸ“¡ Uso de la API

### Endpoint Principal

**POST** `/chat`

Procesa mensajes de usuario y retorna respuestas del chatbot.

#### Request

```http
POST /chat HTTP/1.1
Content-Type: application/json

{
  "message": "Â¿QuÃ© servicios ofrece el laboratorio?"
}
```

#### Response (Ã‰xito)

```http
HTTP/1.1 200 OK
Content-Type: application/json

{
  "response": "El Laboratorio de Co-creaciÃ³n para la InnovaciÃ³n del Instituto Nacional de CancerologÃ­a ofrece diversos servicios..."
}
```

#### Response (Error)

```http
HTTP/1.1 400 Bad Request
Content-Type: application/json

{
  "error": "Falta el mensaje"
}
```

### Ejemplo con cURL

```bash
curl -X POST http://localhost:5003/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hola, Â¿cÃ³mo puedes ayudarme?"}'
```

### Ejemplo con JavaScript (Fetch)

```javascript
const response = await fetch('http://localhost:5003/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    message: 'Â¿CuÃ¡les son los horarios de atenciÃ³n?'
  })
});

const data = await response.json();
console.log(data.response);
```

### Ejemplo con Python (requests)

```python
import requests

response = requests.post('http://localhost:5003/chat', 
  json={'message': 'Â¿CÃ³mo puedo obtener mÃ¡s informaciÃ³n?'})

if response.status_code == 200:
    print(response.json()['response'])
else:
    print(f"Error: {response.json()['error']}")
```

## ğŸ³ Despliegue con Docker

### Crear Dockerfile

```dockerfile
FROM python:3.12-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 5003

CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5003", "run:app"]
```

### Construir y ejecutar

```bash
# Construir imagen
docker build -t chatbot-inc .

# Ejecutar contenedor
docker run -p 5003:5003 -e OPENAI_API_KEY=tu_clave_aqui chatbot-inc
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

| Variable | DescripciÃ³n | Requerida | Valor por defecto |
|----------|-------------|-----------|-------------------|
| `OPENAI_API_KEY` | Clave de API de OpenAI | âœ… SÃ­ | - |
| `FLASK_ENV` | Entorno de Flask | âŒ No | development |
| `PORT` | Puerto del servidor | âŒ No | 5003 |

### ConfiguraciÃ³n de ProducciÃ³n

Para entornos de producciÃ³n, considera:

1. **Usar un servidor WSGI robusto:**
```bash
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:5003 run:app
```

2. **Configurar CORS especÃ­fico:**
```python
# En app/__init__.py
CORS(app, origins=["https://tu-dominio.com"])
```

3. **Implementar rate limiting:**
```bash
pip install Flask-Limiter
```

## ğŸ§ª Testing

### Ejecutar pruebas bÃ¡sicas

```bash
# Verificar que el servidor responde
curl -X POST http://localhost:5003/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "test"}'

# Verificar endpoint de salud (si estÃ¡ implementado)
curl http://localhost:5003/health
```

### Pruebas de carga

```bash
# Usando Apache Bench
ab -n 100 -c 10 -T 'application/json' \
  -p test_data.json http://localhost:5003/chat
```

## ğŸ“Š Monitoreo y Logs

### Habilitar logs detallados

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

### MÃ©tricas importantes a monitorear

- â±ï¸ Tiempo de respuesta por request
- ğŸ“ˆ Volumen de requests por minuto
- ğŸš¨ Tasa de errores
- ğŸ’° Uso de tokens de OpenAI
- ğŸ–¥ï¸ Uso de memoria y CPU

## ğŸ” Troubleshooting

### Problemas comunes

#### âŒ Error: "OpenAI API key not found"
```bash
# Verificar variable de entorno
echo $OPENAI_API_KEY

# Configurar correctamente
export OPENAI_API_KEY=tu_clave_aqui
```

#### âŒ Error: "ModuleNotFoundError: No module named 'openai'"
```bash
# Reinstalar dependencias
pip install -r requirements.txt
```

#### âŒ Error de CORS
```python
# Configurar CORS en app/__init__.py
from flask_cors import CORS
CORS(app, origins=["http://localhost:3000"])
```

### Logs de depuraciÃ³n

Para habilitar modo debug:

```python
# En run.py
if __name__ == "__main__":
    app.run(debug=True, port=5003)
```

## ğŸ¤ Contribuir

### Pasos para contribuir

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear un Pull Request

### EstÃ¡ndares de cÃ³digo

- Seguir PEP 8 para Python
- Documentar funciones y clases
- Incluir tests para nuevas funcionalidades
- Mantener la cobertura de tests

## ğŸ“š DocumentaciÃ³n Adicional

- [Manual TÃ©cnico Completo](MANUAL_TECNICO.md) - DocumentaciÃ³n tÃ©cnica detallada
- [OpenAI API Documentation](https://platform.openai.com/docs) - DocumentaciÃ³n oficial de OpenAI
- [Flask Documentation](https://flask.palletsprojects.com/) - DocumentaciÃ³n de Flask

## ğŸ“‹ Roadmap

### PrÃ³ximas funcionalidades

- [ ] ğŸ” Sistema de autenticaciÃ³n
- [ ] ğŸ“ Logging estructurado
- [ ] ğŸ—„ï¸ Persistencia de conversaciones
- [ ] ğŸ“Š Dashboard de mÃ©tricas
- [ ] ğŸ§ª Suite de tests automatizados
- [ ] ğŸŒ Interfaz web frontend
- [ ] ğŸ”„ Sistema de cachÃ© con Redis
- [ ] ğŸ“± API mÃ³vil optimizada

## â“ FAQ

### Â¿CÃ³mo obtengo una API key de OpenAI?
Visita [platform.openai.com](https://platform.openai.com/) y crea una cuenta. En la secciÃ³n de API keys, genera una nueva clave.

### Â¿Puedo usar otros modelos de OpenAI?
SÃ­, puedes modificar el modelo en `app/openai_service.py` cambiando `gpt-4o-mini` por otro modelo disponible.

### Â¿El chatbot almacena las conversaciones?
Actualmente no, cada request es independiente. La persistencia estÃ¡ planificada para futuras versiones.

### Â¿CÃ³mo cambio el puerto del servidor?
Modifica el puerto en `run.py` o usa la variable de entorno `PORT`.

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¤ Autor

**Kevin Steven PÃ©rez** - Ingeniero de Sistemas  
Laboratorio de Co-creaciÃ³n para la InnovaciÃ³n  
Instituto Nacional de CancerologÃ­a

---

## ğŸ¥ Sobre el Instituto Nacional de CancerologÃ­a

El Instituto Nacional de CancerologÃ­a es una instituciÃ³n lÃ­der en Colombia dedicada a la prevenciÃ³n, diagnÃ³stico, tratamiento e investigaciÃ³n del cÃ¡ncer. El Laboratorio de Co-creaciÃ³n para la InnovaciÃ³n trabaja en el desarrollo de soluciones tecnolÃ³gicas innovadoras para mejorar la atenciÃ³n mÃ©dica y la experiencia de los pacientes.

---

â­ Si este proyecto te resulta Ãºtil, Â¡considera darle una estrella en GitHub!

ğŸ“ Para soporte tÃ©cnico o consultas, contacta al equipo de desarrollo del Laboratorio de Co-creaciÃ³n.
